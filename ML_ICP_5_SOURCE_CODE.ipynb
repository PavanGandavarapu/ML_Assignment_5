{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.27231177 0.20374308]\n",
      "Silhouette score of Original Data: 0.24778944198785616\n",
      "Silhouette score of k-means + PCA data: 0.4446068833433421\n",
      "Silhouette score improved after applying k-means on PCA data\n",
      "Silhouette Score with Scaling + PCA + K-Means: 0.4446069857480921\n",
      "Silhouette score of k-means + PCA data: 0.4446068833433421\n",
      "Silhouette score improved after applying Scaling + PCA + K-Means\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/gowth/Desktop/UCM/ML/Assignment 5/datasets/CC_GENERAL.csv\")\n",
    "\n",
    "# Drop the irrelevant columns\n",
    "df = df.drop([\"CUST_ID\"], axis=1)\n",
    "\n",
    "# Handle the missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Apply k-means algorithm on the original data\n",
    "kmeans_orig = KMeans(n_clusters=3)\n",
    "kmeans_orig.fit(scaled_data)\n",
    "\n",
    "# Compute the silhouette score on the original data\n",
    "silhouette_score_orig = silhouette_score(scaled_data, kmeans_orig.labels_)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Analyze the variance explained by each principal component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio:\", explained_variance)\n",
    "\n",
    "# Apply k-means algorithm on the PCA data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(pca_data)\n",
    "\n",
    "# Compute the silhouette score on the PCA data\n",
    "silhouette_score_pca = silhouette_score(pca_data, kmeans.labels_)\n",
    "\n",
    "# Compare the silhouette score\n",
    "print(\"Silhouette score of Original Data:\", silhouette_score_orig)\n",
    "print(\"Silhouette score of k-means + PCA data:\", silhouette_score_pca)\n",
    "if silhouette_score_pca > silhouette_score_orig:\n",
    "    print(\"Silhouette score improved after applying k-means on PCA data\")\n",
    "else:\n",
    "    print(\"Silhouette score did not improve after applying k-means on PCA data\")\n",
    "    \n",
    "\n",
    "# Perform Scaling + PCA + K-Means\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(pca_data)\n",
    "\n",
    "silhouette_score_scaled_pca_kmeans = silhouette_score(pca_data, kmeans.labels_)\n",
    "\n",
    "\n",
    "# Compare the silhouette score\n",
    "print(\"Silhouette Score with Scaling + PCA + K-Means:\", silhouette_score_scaled_pca_kmeans)\n",
    "print(\"Silhouette score of k-means + PCA data:\", silhouette_score_pca)\n",
    "if silhouette_score_scaled_pca_kmeans > silhouette_score_pca:\n",
    "    print(\"Silhouette score improved after applying Scaling + PCA + K-Means\")\n",
    "else:\n",
    "    print(\"Silhouette score did not improve after applying Scaling + PCA + K-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "#2. Use pd_speech_features.csv\n",
    "    #a. Perform Scaling\n",
    "    #b. Apply PCA (k=3)\n",
    "    #c. Use SVM to report performance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/gowth/Desktop/UCM/ML/Assignment 5/datasets/pd_speech_features.csv', skiprows=1)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA with k=3\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X_pca[:split]\n",
    "X_test = X_pca[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "# Train an SVM classifier on the training set\n",
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris.csv data before LDA Transformation:\n",
      "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "Iris.csv data after LDA Transformation:\n",
      "        LDA1      LDA2      Species\n",
      "0 -8.084953  0.328454  Iris-setosa\n",
      "1 -7.147163 -0.755473  Iris-setosa\n",
      "2 -7.511378 -0.238078  Iris-setosa\n",
      "3 -6.837676 -0.642885  Iris-setosa\n",
      "4 -8.157814  0.540639  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# 3. Apply Linear Discriminant Analysis (LDA) on Iris.csv dataset to reduce dimensionality of data tok=2.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "iris_df = pd.read_csv('C:/Users/gowth/Desktop/UCM/ML/Assignment 5/datasets/Iris.csv')\n",
    "X = iris_df.drop(['Id', 'Species'], axis=1).values\n",
    "y = iris_df['Species'].values\n",
    "\n",
    "print(\"Iris.csv data before LDA Transformation:\\n\", iris_df.head())\n",
    "\n",
    "# Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# Apply LDA to the standardized data\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X_std, y)\n",
    "\n",
    "# Save the LDA-transformed data to a CSV file\n",
    "iris_lda_df = pd.DataFrame(data=X_lda, columns=['LDA1', 'LDA2'])\n",
    "iris_lda_df['Species'] = y\n",
    "iris_lda_df.to_csv('Iris_LDA.csv', index=False)\n",
    "\n",
    "# Display the LDA-transformed data\n",
    "print(\"Iris.csv data after LDA Transformation:\\n\",iris_lda_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
